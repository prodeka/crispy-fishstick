# üéØ **PLAN D'ACTION HARMONIEUX - AM√âLIORATION V10**
## **Int√©gration Harmonieuse avec l'Existant - Optimisation des R√©servoirs Sur√©lev√©s**

---

## üìã **ANALYSE DE L'EXISTANT ET STRAT√âGIE D'INT√âGRATION**

### **‚úÖ Ce qui existe d√©j√† et qu'on peut r√©utiliser :**
- **Structure CLI** : Commande `lcpi aep network-optimize-unified` d√©j√† impl√©ment√©e
- **Algorithme g√©n√©tique** : `GeneticOptimizer` dans `src/lcpi/aep/optimization/`
- **Mod√®les Pydantic** : `ConfigurationOptimisation`, `ContraintesTechniques` dans `models.py`
- **Gestionnaire de contraintes** : `ConstraintManager` d√©j√† impl√©ment√©
- **Solveurs** : `SolverFactory` avec support `lcpi` et `epanet`
- **Base de donn√©es AEP** : Syst√®me de gestion des projets et donn√©es
- **Syst√®me de rapports** : Int√©gration avec `lcpi rapport`
- **Logging et int√©grit√©** : Syst√®me de journalisation existant
- **Validation des donn√©es** : Syst√®me de validation YAML/INP existant

### **üîÑ Ce qu'il faut adapter et √©tendre :**
- **Structure des commandes** : Ajouter les nouvelles commandes `tank-*` sans conflit
- **Architecture d'optimisation** : √âtendre le syst√®me existant avec de nouveaux algorithmes
- **Int√©gration EPANET** : Am√©liorer le wrapper existant pour l'optimisation des r√©servoirs
- **Nouvelles m√©thodes** : Impl√©menter binary, nested, global, surrogate

---

## üèóÔ∏è **ARCHITECTURE ET ORGANISATION DU CODE**

### **Structure des dossiers (Extension harmonieuse) :**
```
src/lcpi/aep/
‚îú‚îÄ optimization/                    # ‚úÖ EXISTANT - NE PAS TOUCHER
‚îÇ  ‚îú‚îÄ genetic_algorithm.py         # ‚úÖ EXISTANT - NE PAS TOUCHER
‚îÇ  ‚îú‚îÄ models.py                    # ‚úÖ EXISTANT - NE PAS TOUCHER
‚îÇ  ‚îú‚îÄ constraints.py               # ‚úÖ EXISTANT - NE PAS TOUCHER
‚îÇ  ‚îî‚îÄ individual.py                # ‚úÖ EXISTANT - NE PAS TOUCHER
‚îú‚îÄ optimizer/                       # üÜï NOUVEAU - Extension harmonieuse
‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îú‚îÄ controllers.py               # üÜï Orchestrateur principal
‚îÇ  ‚îú‚îÄ algorithms/                  # üÜï Nouveaux algorithmes
‚îÇ  ‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îÇ  ‚îú‚îÄ binary.py                 # üÜï Recherche binaire pour H_tank
‚îÇ  ‚îÇ  ‚îú‚îÄ nested.py                 # üÜï Nested greedy pour diam√®tres + hauteur
‚îÇ  ‚îÇ  ‚îú‚îÄ global_opt.py             # üÜï Wrapper autour de l'existant
‚îÇ  ‚îÇ  ‚îî‚îÄ surrogate.py              # üÜï Mod√®les IA pour acc√©l√©ration
‚îÇ  ‚îú‚îÄ solvers/                     # üÜï Extension des solveurs
‚îÇ  ‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îÇ  ‚îú‚îÄ epanet_optimizer.py       # üÜï Wrapper EPANET pour optimisation
‚îÇ  ‚îÇ  ‚îî‚îÄ lcpi_optimizer.py         # üÜï Wrapper LCPI pour optimisation
‚îÇ  ‚îú‚îÄ scoring.py                   # üÜï Calcul des co√ªts CAPEX/OPEX
‚îÇ  ‚îú‚îÄ cache.py                     # üÜï Syst√®me de cache intelligent
‚îÇ  ‚îú‚îÄ validators.py                # üÜï Validation d'int√©grit√©
‚îÇ  ‚îú‚îÄ io.py                        # üÜï Lecture YAML/INP -> internal model
‚îÇ  ‚îî‚îÄ models.py                    # üÜï Mod√®les Pydantic √©tendus
‚îú‚îÄ data/                           # üÜï Base de donn√©es diam√®tres
‚îÇ  ‚îú‚îÄ diameters.yml                # üÜï DB initiale des diam√®tres
‚îÇ  ‚îî‚îÄ model_store/                 # üÜï Stockage des mod√®les surrogate
‚îî‚îÄ tests/                          # üÜï Tests des nouvelles fonctionnalit√©s
   ‚îú‚îÄ test_binary.py
   ‚îú‚îÄ test_nested.py
   ‚îú‚îÄ test_surrogate.py
   ‚îî‚îÄ test_integration.yml
```

---

## üöÄ **M√âTHODES D'OPTIMISATION √Ä D√âVELOPPER**

### **1. ALGORITHME BINARY (Recherche Binaire)**
**Fichier :** `src/lcpi/aep/optimizer/algorithms/binary.py`

#### **Fonctionnalit√©s :**
- **Recherche binaire** pour optimiser H_tank (hauteur du r√©servoir)
- **Convergence rapide** sur des probl√®mes 1D (hauteur uniquement)
- **Validation automatique** des contraintes de pression
- **Int√©gration** avec les solveurs existants

#### **API :**
```python
class BinarySearchOptimizer:
    def __init__(self, network_model, pressure_constraints, diameter_db):
        self.network = network_model
        self.pressure_min = pressure_constraints.min_pressure
        self.diameter_db = diameter_db
    
    def optimize_tank_height(self, H_min: float, H_max: float, tolerance: float = 0.1) -> Dict:
        """
        Optimise la hauteur du r√©servoir par recherche binaire.
        
        Args:
            H_min: Hauteur minimale du r√©servoir (m)
            H_max: Hauteur maximale du r√©servoir (m)
            tolerance: Tol√©rance de convergence (m)
        
        Returns:
            Dict avec H_optimal, pressions, vitesses, co√ªts
        """
        pass
```

#### **Algorithme :**
1. **Initialisation** : H_low = H_min, H_high = H_max
2. **Boucle principale** : Tant que (H_high - H_low) > tolerance
3. **Test milieu** : H_mid = (H_low + H_high) / 2
4. **Simulation** : Tester H_mid avec solveur EPANET/LCPI
5. **Validation** : V√©rifier contraintes de pression
6. **Mise √† jour** : Ajuster H_low ou H_high selon le r√©sultat
7. **Convergence** : Retourner la meilleure solution

---

### **2. ALGORITHME NESTED (Nested Greedy)**
**Fichier :** `src/lcpi/aep/optimizer/algorithms/nested.py`

#### **Fonctionnalit√©s :**
- **Optimisation en deux √©tapes** : H_tank puis diam√®tres
- **Heuristique gloutonne** pour la s√©lection des diam√®tres
- **Int√©gration** avec la base de donn√©es des diam√®tres existante
- **Validation multi-crit√®res** (pression, vitesse, co√ªt)

#### **API :**
```python
class NestedGreedyOptimizer:
    def __init__(self, network_model, diameter_db, cost_model):
        self.network = network_model
        self.diameter_db = diameter_db
        self.cost_model = cost_model
    
    def optimize_nested(self, H_bounds: Tuple[float, float], 
                       pressure_constraints: Dict,
                       cost_constraints: Dict) -> Dict:
        """
        Optimisation en deux √©tapes : hauteur puis diam√®tres.
        
        Args:
            H_bounds: (H_min, H_max) en m√®tres
            pressure_constraints: Contraintes de pression
            cost_constraints: Contraintes de co√ªt
        
        Returns:
            Dict avec H_optimal, diameters_optimal, m√©triques compl√®tes
        """
        pass
    
    def _optimize_tank_height(self, H_bounds: Tuple[float, float]) -> float:
        """√âtape 1: Optimisation de la hauteur du r√©servoir."""
        pass
    
    def _optimize_diameters(self, H_tank: float) -> Dict[str, int]:
        """√âtape 2: Optimisation des diam√®tres pour H_tank fix√©."""
        pass
```

#### **Algorithme :**
1. **√âtape 1 - Hauteur** : Utiliser binary search pour H_tank optimal
2. **√âtape 2 - Diam√®tres** : Pour chaque conduite, s√©lectionner le diam√®tre optimal
3. **S√©lection gloutonne** : Choisir le diam√®tre qui maximise le ratio performance/co√ªt
4. **Validation** : V√©rifier toutes les contraintes
5. **Optimisation** : Ajuster it√©rativement si n√©cessaire

---

### **3. ALGORITHME GLOBAL (Wrapper autour de l'Existant)**
**Fichier :** `src/lcpi/aep/optimizer/algorithms/global_opt.py`

#### **Fonctionnalit√©s :**
- **Wrapper intelligent** autour de `GeneticOptimizer` existant
- **Extension** pour inclure H_tank dans l'optimisation
- **Parall√©lisation** avec `concurrent.futures.ProcessPoolExecutor`
- **Int√©gration** avec le syst√®me de cache existant

#### **API :**
```python
class GlobalOptimizer:
    """Wrapper autour de l'algorithme g√©n√©tique existant."""
    
    def __init__(self, config: ConfigurationOptimisation):
        # R√©utiliser l'optimiseur existant
        from ...optimization.genetic_algorithm import GeneticOptimizer
        self.genetic_optimizer = GeneticOptimizer(config, ...)
    
    def optimize_global(self, network_data: Dict, 
                       tank_constraints: Dict,
                       parallel_workers: int = 4) -> Dict:
        """
        Optimisation globale avec algorithme g√©n√©tique existant.
        
        Args:
            network_data: Donn√©es du r√©seau (r√©utilise l'existant)
            tank_constraints: Contraintes sp√©cifiques au r√©servoir
            parallel_workers: Nombre de workers parall√®les
        
        Returns:
            R√©sultat de l'optimisation avec m√©triques compl√®tes
        """
        pass
    
    def _extend_individual_for_tank(self, individual: 'Individu') -> 'TankIndividual':
        """√âtend l'individu existant pour inclure H_tank."""
        pass
```

#### **Int√©gration avec l'existant :**
- **R√©utiliser** `GeneticOptimizer.optimiser()` existant
- **√âtendre** la classe `Individu` existante avec H_tank
- **Adapter** `ConstraintManager` existant pour les contraintes de r√©servoir
- **Conserver** la logique de fitness existante

---

### **4. ALGORITHME SURROGATE (Mod√®les IA)**
**Fichier :** `src/lcpi/aep/optimizer/algorithms/surrogate.py`

#### **Fonctionnalit√©s :**
- **Mod√®les de substitution** pour acc√©l√©rer l'optimisation
- **XGBoost/RandomForest** pour pr√©dictions rapides
- **Active Learning** pour am√©lioration it√©rative
- **Validation** sur solveur r√©el pour les meilleures solutions

#### **API :**
```python
class SurrogateOptimizer:
    def __init__(self, network_model, solver_type: str = "epanet"):
        self.network = network_model
        self.solver_type = solver_type
        self.surrogate_model = None
        self.dataset = []
    
    def build_and_optimize(self, H_bounds: Tuple[float, float],
                          diameter_candidates: List[int],
                          n_initial_samples: int = 200,
                          n_validation: int = 10) -> Dict:
        """
        Construction et optimisation avec mod√®le surrogate.
        
        Args:
            H_bounds: Bornes de hauteur du r√©servoir
            diameter_candidates: Diam√®tres candidats
            n_initial_samples: Nombre d'√©chantillons initiaux
            n_validation: Nombre de solutions √† valider
        
        Returns:
            R√©sultat optimis√© avec validation sur solveur r√©el
        """
        pass
    
    def _generate_initial_dataset(self, n_samples: int) -> List[Dict]:
        """G√©n√©ration du dataset initial avec Latin Hypercube Sampling."""
        pass
    
    def _train_surrogate_model(self, X: np.ndarray, y: np.ndarray) -> Any:
        """Entra√Ænement du mod√®le surrogate (XGBoost/RandomForest)."""
        pass
    
    def _optimize_on_surrogate(self, n_candidates: int = 1000) -> List[Dict]:
        """Optimisation rapide sur le mod√®le surrogate."""
        pass
    
    def _validate_candidates(self, candidates: List[Dict]) -> List[Dict]:
        """Validation des meilleures solutions sur le solveur r√©el."""
        pass
```

#### **Pipeline d'optimisation :**
1. **G√©n√©ration dataset** : Latin Hypercube Sampling (200-1000 √©chantillons)
2. **Entra√Ænement mod√®le** : XGBoost/RandomForest sur features r√©seau
3. **Optimisation surrogate** : Test de 1000+ candidats en quelques secondes
4. **S√©lection top-K** : Choisir les K meilleures solutions
5. **Validation r√©elle** : Tester top-K sur solveur EPANET/LCPI
6. **Active Learning** : Ajouter r√©sultats au dataset et r√©entra√Æner

---

## üîß **EXTENSION DES SOLVEURS EXISTANTS**

### **1. Wrapper EPANET pour Optimisation**
**Fichier :** `src/lcpi/aep/optimizer/solvers/epanet_optimizer.py`

#### **Fonctionnalit√©s :**
- **Modification dynamique** des fichiers .inp
- **Gestion des sections** [TANKS], [RESERVOIRS], [PIPES]
- **Int√©gration** avec `wntr.epanet` existant
- **Cache intelligent** des simulations

#### **API :**
```python
class EPANETOptimizer:
    """Wrapper EPANET pour l'optimisation des r√©servoirs."""
    
    def __init__(self):
        # R√©utiliser la factory existante
        from ...core.solvers import SolverFactory
        self.solver = SolverFactory.get_solver("epanet")
        self.cache = {}
    
    def simulate_with_tank_height(self, network_model: Dict, 
                                 H_tank: float, 
                                 diameters: Dict[str, int]) -> Dict:
        """
        Simulation avec hauteur de r√©servoir et diam√®tres modifi√©s.
        
        Args:
            network_model: Mod√®le r√©seau (YAML ou INP)
            H_tank: Hauteur du r√©servoir (m)
            diameters: Mapping {link_id: diameter_mm}
        
        Returns:
            R√©sultats de simulation (pressions, vitesses, etc.)
        """
        pass
    
    def _modify_inp_file(self, inp_path: Path, H_tank: float, 
                         diameters: Dict[str, int]) -> Path:
        """Modifie le fichier INP avec nouvelles valeurs."""
        pass
    
    def _extract_results(self, simulation_output: Any) -> Dict:
        """Extrait les r√©sultats de simulation EPANET."""
        pass
```

### **2. Wrapper LCPI pour Optimisation**
**Fichier :** `src/lcpi/aep/optimizer/solvers/lcpi_optimizer.py`

#### **Fonctionnalit√©s :**
- **Adaptation** du solveur LCPI existant pour l'optimisation
- **Modification** des mod√®les de r√©seau
- **Int√©gration** avec `HardyCross` existant
- **Validation** des contraintes

---

## üìä **SYST√àME DE SCORING ET CO√õTS**

### **Fichier :** `src/lcpi/aep/optimizer/scoring.py`

#### **Fonctionnalit√©s :**
- **Calcul CAPEX** : Longueur √ó Co√ªt par m√®tre (diam√®tre)
- **Calcul OPEX** : Estimation √©nerg√©tique annuelle
- **P√©nalit√©s** : Violations de contraintes
- **Multi-objectifs** : Pareto front (co√ªt vs performance)

#### **API :**
```python
class CostScorer:
    def __init__(self, diameter_cost_db: Dict[int, float], 
                 energy_cost_kwh: float = 0.15):
        self.diameter_costs = diameter_cost_db
        self.energy_cost = energy_cost_kwh
    
    def compute_total_cost(self, network: Dict, 
                          diameters: Dict[str, int],
                          H_tank: float) -> Dict[str, float]:
        """
        Calcul du co√ªt total (CAPEX + OPEX).
        
        Returns:
            Dict avec CAPEX, OPEX_annual, total_cost
        """
        pass
    
    def compute_capex(self, network: Dict, diameters: Dict[str, int]) -> float:
        """Calcul du co√ªt d'investissement (CAPEX)."""
        pass
    
    def compute_opex(self, network: Dict, H_tank: float) -> float:
        """Estimation des co√ªts d'exploitation (OPEX)."""
        pass
```

---

## üóÑÔ∏è **SYST√àME DE CACHE ET PERFORMANCE**

### **Fichier :** `src/lcpi/aep/optimizer/cache.py`

#### **Fonctionnalit√©s :**
- **Cache intelligent** bas√© sur hash des param√®tres
- **Gestion m√©moire** avec LRU (Least Recently Used)
- **Persistance** sur disque pour sessions longues
- **Int√©gration** avec le syst√®me de cache existant

#### **API :**
```python
class OptimizationCache:
    def __init__(self, max_size: int = 1000, persist_path: Optional[Path] = None):
        self.max_size = max_size
        self.cache = {}
        self.persist_path = persist_path
    
    def get_cached_result(self, network_hash: str, 
                         H_tank: float, 
                         diameters_hash: str) -> Optional[Dict]:
        """R√©cup√®re un r√©sultat en cache."""
        pass
    
    def cache_result(self, network_hash: str, H_tank: float, 
                    diameters_hash: str, result: Dict) -> None:
        """Met en cache un r√©sultat."""
        pass
    
    def _compute_hash(self, network_model: Dict, 
                     H_tank: float, 
                     diameters: Dict[str, int]) -> str:
        """Calcule le hash des param√®tres d'entr√©e."""
        pass
```

---

## üîç **VALIDATION ET INT√âGRIT√â**

### **Fichier :** `src/lcpi/aep/optimizer/validators.py`

#### **Fonctionnalit√©s :**
- **V√©rification d'int√©grit√©** des fichiers .inp/.yml
- **Validation m√©tier** des contraintes
- **Checksum SHA256** et signatures
- **Int√©gration** avec le syst√®me d'int√©grit√© existant

#### **API :**
```python
class NetworkValidator:
    def __init__(self):
        self.integrity_manager = None  # R√©utiliser l'existant
    
    def check_network_integrity(self, network_path: Path) -> Dict[str, Any]:
        """
        V√©rifie l'int√©grit√© et la validit√© du r√©seau.
        
        Returns:
            Dict avec status, errors, warnings, metadata
        """
        pass
    
    def validate_business_rules(self, network_model: Dict) -> List[str]:
        """Valide les r√®gles m√©tier du r√©seau."""
        pass
    
    def verify_epanet_compatibility(self, inp_path: Path) -> bool:
        """V√©rifie la compatibilit√© EPANET."""
        pass
```

---

## üéØ **COMMANDES CLI FINALES (Int√©gr√©es √† l'Existant)**

### **Structure des commandes (Ajout harmonieux) :**
```python
# Dans src/lcpi/aep/commands/main.py - AJOUTER sans remplacer
from .tank_optimization import app as tank_optimization_app

# Ajouter aux sous-commandes existantes
app.add_typer(tank_optimization_app, name="tank", help="üèóÔ∏è Optimisation des r√©servoirs sur√©lev√©s")
app.add_typer(network_optimize_app, name="network", help="üåê Optimisation des r√©seaux")  # ‚úÖ EXISTANT
```

### **Nouvelles commandes disponibles :**
```bash
# Commandes existantes (NE PAS TOUCHER)
lcpi aep network-optimize-unified    # ‚úÖ EXISTANT
lcpi aep hardy-cross                 # ‚úÖ EXISTANT
lcpi aep simulate-inp                # ‚úÖ EXISTANT

# Nouvelles commandes (AJOUT√âES)
lcpi aep tank optimize               # üÜï Optimisation r√©servoir
lcpi aep tank verify                 # üÜï V√©rification int√©grit√©
lcpi aep tank simulate               # üÜï Simulation unique
lcpi aep tank auto-optimize          # üÜï Pipeline complet
lcpi aep tank diameters-manage       # üÜï Gestion base diam√®tres
lcpi aep tank price-optimize         # üÜï Optimisation par co√ªt
```

### **Exemples d'utilisation :**
```bash
# Optimisation basique avec m√©thode nested
lcpi aep tank optimize network.yml --method nested --solver epanet

# Optimisation avec contraintes de co√ªt
lcpi aep tank optimize network.yml --method global --objective price --budget 100000

# Pipeline automatique complet
lcpi aep tank auto-optimize network.inp --config config.yml --solver epanet

# V√©rification d'int√©grit√©
lcpi aep tank verify network.inp

# Simulation unique pour validation
lcpi aep tank simulate network.yml --H 63.2 --diameters diam.yml
```

---

## üîÑ **INT√âGRATION AVEC L'√âCOSYST√àME EXISTANT**

### **1. R√©utilisation du syst√®me de base de donn√©es AEP :**
- **Utiliser** les mod√®les de projet existants
- **Int√©grer** avec le syst√®me de validation existant
- **R√©utiliser** la gestion des m√©tadonn√©es existante

### **2. Int√©gration avec le syst√®me de rapports :**
```python
# src/lcpi/aep/optimizer/controllers.py
from ...reporting import ReportGenerator  # ‚úÖ EXISTANT

class TankOptimizationController:
    def generate_report(self, result):
        # Utiliser le syst√®me de rapports existant
        report_gen = ReportGenerator()
        return report_gen.generate_optimization_report(result)
```

### **3. R√©utilisation du syst√®me de logging :**
- **Utiliser** le syst√®me de journalisation existant
- **Int√©grer** avec le gestionnaire d'int√©grit√© existant
- **R√©utiliser** les formats de sortie existants

---

## üóÇÔ∏è **FORMATS DE SORTIE ET INT√âGRATION RAPPORTS**

### **Format JSON standardis√© :**
```json
{
  "meta": {
    "method": "nested",
    "solver": "epanet",
    "timestamp": "2025-08-18T...",
    "seed": 42,
    "version": "2.1.0"
  },
  "optimization_results": {
    "H_tank_m": 63.2,
    "diameters_mm": {"pipe_1": 110, "pipe_2": 160},
    "pressures_m": {"node_001": 15.2, "node_002": 12.8},
    "velocities_m_s": {"pipe_1": 1.1, "pipe_2": 0.8}
  },
  "costs": {
    "CAPEX": 123450.0,
    "OPEX_annual": 3456.0,
    "total_cost": 126906.0
  },
  "constraints": {
    "pressure_min_ok": true,
    "velocity_limits_ok": true,
    "violations": []
  },
  "simulation_files": {
    "epanet_inp": "results/opt_sim.inp",
    "epanet_out": "results/opt_sim.out"
  },
  "report_payload": {
    "template": "optimisation_tank.jinja2",
    "placeholders": {
      "methode_utilisee": "nested",
      "contrainte_pression_min": "10.0 m",
      "cout_total": "126,906 FCFA"
    }
  }
}
```

### **Int√©gration avec `lcpi rapport` :**
- **Template** `optimisation_tank.jinja2` pour les rapports
- **Placeholders** automatiques dans les templates existants
- **G√©n√©ration** de tableaux, graphiques et cartes
- **Int√©gration** avec les workflows de rapport existants

---

## üß™ **TESTS ET VALIDATION**

### **Tests unitaires :**
- **`test_binary.py`** : Tests de convergence de la recherche binaire
- **`test_nested.py`** : Tests de l'algorithme nested greedy
- **`test_surrogate.py`** : Tests des mod√®les IA
- **`test_integration.py`** : Tests end-to-end

### **Sc√©narios de test :**
- **Sc√©nario A** : R√©seau 1 tuyau analytique ‚Üí v√©rifier binary
- **Sc√©nario B** : Petit r√©seau EPANET 5 n≈ìuds ‚Üí nested greedy
- **Sc√©nario C** : Budget contraint ‚Üí objective price
- **Sc√©nario D** : Surrogate warmstart ‚Üí validate top 5

### **Tests de compatibilit√© :**
- **V√©rifier** que `lcpi aep network-optimize-unified` fonctionne toujours
- **Tester** que les anciens projets AEP sont toujours compatibles
- **Valider** que les rapports existants continuent de fonctionner

---

## üöÄ **ROADMAP D√âTAILL√âE D'IMPL√âMENTATION**

### **Sprint 1 (Semaine 1-2) : Architecture et Extension**
- ‚úÖ Cr√©er la structure `optimizer/` sans toucher √† l'existant
- ‚úÖ √âtendre les mod√®les Pydantic existants
- ‚úÖ Cr√©er le contr√¥leur principal
- ‚úÖ Impl√©menter l'algorithme binary (recherche binaire)
- ‚úÖ Tests unitaires de base

### **Sprint 2 (Semaine 3-4) : Algorithmes et Solveurs**
- ‚úÖ Impl√©menter l'algorithme nested (nested greedy)
- ‚úÖ Cr√©er le wrapper global autour de l'existant
- ‚úÖ Cr√©er les wrappers de solveurs EPANET/LCPI
- ‚úÖ Syst√®me de scoring CAPEX/OPEX
- ‚úÖ Tests d'int√©gration des algorithmes

### **Sprint 3 (Semaine 5-6) : IA et Surrogate**
- ‚úÖ Impl√©menter l'algorithme surrogate (XGBoost/RandomForest)
- ‚úÖ Syst√®me de cache intelligent
- ‚úÖ Pipeline d'active learning
- ‚úÖ Validation des mod√®les IA
- ‚úÖ Tests de performance

### **Sprint 4 (Semaine 7-8) : Int√©gration CLI et Tests**
- ‚úÖ Ajouter les nouvelles commandes CLI
- ‚úÖ Int√©gration avec l'√©cosyst√®me existant
- ‚úÖ Tests de compatibilit√©
- ‚úÖ Documentation utilisateur
- ‚úÖ Exemples et templates

---

## üîí **S√âCURIT√â ET INT√âGRIT√â**

### **V√©rifications d'int√©grit√© :**
- **SHA256** des fichiers .inp/.yml
- **Signatures** optionnelles avec fichiers .sig
- **Validation** des sch√©mas Pydantic
- **Journalisation** de tous les runs d'optimisation

### **Gestion des erreurs :**
- **Timeouts** sur les simulations longues
- **Retry logic** pour les √©checs temporaires
- **Fallback** vers solveur de secours
- **Logging** d√©taill√© des erreurs

---

## üìà **MONITORING ET PERFORMANCE**

### **M√©triques de performance :**
- **Temps de simulation** par solveur
- **Taux de cache hit** pour les optimisations
- **Convergence** des algorithmes
- **Qualit√©** des solutions surrogate

### **Optimisations futures :**
- **Parall√©lisation** avanc√©e avec Dask
- **GPU acceleration** pour les mod√®les IA
- **Distributed computing** pour gros r√©seaux
- **Real-time optimization** avec streaming

---

## üéØ **AVANTAGES DE CETTE APPROCHE HARMONIEUSE**

### **‚úÖ Pour les d√©veloppeurs :**
- **R√©utilisation maximale** du code existant
- **Pas de r√©gression** sur les fonctionnalit√©s existantes
- **Architecture coh√©rente** avec l'existant
- **Tests plus faciles** gr√¢ce √† la compatibilit√©

### **‚úÖ Pour les utilisateurs :**
- **Commandes famili√®res** dans la m√™me structure
- **Projets existants** toujours compatibles
- **Nouvelles fonctionnalit√©s** sans apprentissage
- **Int√©gration transparente** avec l'√©cosyst√®me

### **‚úÖ Pour la maintenance :**
- **Code centralis√©** et bien organis√©
- **D√©pendances claires** et ma√Ætris√©es
- **√âvolutions futures** plus faciles
- **Documentation coh√©rente**

---

## üîÆ **√âVOLUTIONS FUTURES (V11+)**

### **Fonctionnalit√©s avanc√©es :**
- **Multi-r√©servoirs** : Optimisation de plusieurs r√©servoirs
- **Pompes variables** : Optimisation des courbes de pompage
- **Demandes dynamiques** : Patterns de demande temporels
- **R√©silience** : Optimisation pour la robustesse

### **Int√©grations avanc√©es :**
- **GIS** : Optimisation avec donn√©es g√©ospatiales
- **BIM** : Int√©gration avec la maquette num√©rique
- **IoT** : Optimisation en temps r√©el
- **Cloud** : Optimisation distribu√©e

---

Plut√¥t que rester √† la th√©orie, je te livre maintenant **un plan d‚Äôaction concret + un artefact pr√™t √† coller** : un **squelette CLI Typer** + une **impl√©mentation fonctionnelle de la m√©thode `binary`** (avec solver mock pour tester sans EPANET), les **stubs** n√©cessaires (I/O, validateur, DB diam√®tres) et un **exemple de `config.yml` / `diameters.yml`**.

Tu pourras l‚Äôint√©grer dans `src/lcpi/aep/` et √ßa te permettra de valider l‚Äôarchitecture, les flux, la signature/log, l‚ÄôIO et le format de sortie avant d‚Äôimpl√©menter les algos plus lourds (`nested`, `global`, `surrogate`) et les wrappers EPANET.

---

# Ce que je te fournis maintenant

1. **Squelette CLI** (Typer) avec commandes :
    
    - `lcpi aep tank optimize` (point d‚Äôentr√©e, appelle binary pour l‚Äôinstant)
        
    - `lcpi aep tank verify`
        
    - `lcpi aep tank simulate`
        
    - `lcpi aep tank auto-optimize` (pipeline simple : verify ‚Üí optimize ‚Üí save)
        
2. **BinarySearchOptimizer** fonctionnel (utilise un `Solver` abstrait ; j‚Äôinclus un `MockSolver` pour tests).
    
3. **I/O minimal** : loader YAML / INP (INP : int√©grit√© via checksum SHA256), Pydantic `NetworkModel` minimal.
    
4. **Validators** basiques (int√©grit√© + checks m√©tier simples).
    
5. **Fichiers d‚Äôexemple** : `config.yml`, `diameters.yml`.
    
6. **Format de sortie JSON** standardis√© (compatible `lcpi rapport` placeholders).
    
7. **Instructions courtes** pour ex√©cuter/tester localement.
    

Tu pourras ensuite remplacer `MockSolver` par `EPANETOptimizer` (wrapper wntr/epanet) ou `LCPI` solver.

---

# Code pr√™t √† coller

Colle ce fichier dans `src/lcpi/plugins/aep/tank_cli.py` (ou adapte l‚Äôemplacement que tu pr√©f√®res).  
(Il est autonome pour tests ‚Äî ne d√©pend pas d‚ÄôEPANET.)

```python
# src/lcpi/plugins/aep/tank_cli.py
import json
import hashlib
from pathlib import Path
from typing import Dict, Optional, Tuple, Any
from dataclasses import dataclass
import typer
import yaml
from pydantic import BaseModel, Field, validator
from datetime import datetime

app = typer.Typer(help="üèóÔ∏è Optimisation des r√©servoirs sur√©lev√©s (lcpi aep)")

# -------------------------
# Models
# -------------------------
class PressureConstraints(BaseModel):
    min_pressure_m: float = Field(..., gt=0, description="Pression minimale requise (mCE)")

class SolverConfig(BaseModel):
    type: str = Field("mock", description="mock | epanet | lcpi")
    duration_h: int = 24
    time_step_min: int = 5

class OptimizationConfig(BaseModel):
    method: str = Field("binary", description="binary | nested | global | surrogate")
    H_bounds_m: Optional[Tuple[float, float]] = None
    H_fixed_m: Optional[float] = None
    tolerance_m: float = 0.1
    max_iterations: int = 60
    velocity_min_m_s: float = 0.6
    velocity_max_m_s: float = 2.0
    diameter_db: str = "data/diameters.yml"

    @validator("method")
    def method_allowed(cls, v):
        if v not in ("binary","nested","global","surrogate"):
            raise ValueError("method must be one of binary|nested|global|surrogate")
        return v

class NetworkModel(BaseModel):
    """Mod√®le minimal attendu apr√®s parsing INP/YAML."""
    nodes: Dict[str, Dict[str, Any]] = {}
    links: Dict[str, Dict[str, Any]] = {}
    tanks: Dict[str, Dict[str, Any]] = {}

# -------------------------
# I/O and Validators
# -------------------------
def sha256_of_file(path: Path) -> str:
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()

class NetworkValidator:
    def __init__(self):
        pass

    def check_integrity(self, path: Path) -> Dict[str, Any]:
        """V√©rifie pr√©sence et calcule checksum. (Signature possible plus tard)"""
        if not path.exists():
            return {"ok": False, "errors": ["file not found"]}
        checksum = sha256_of_file(path)
        return {"ok": True, "checksum": checksum, "path": str(path)}

    def validate_model(self, model: NetworkModel) -> Dict[str, Any]:
        errors = []
        if not model.nodes:
            errors.append("No nodes found")
        if not model.links:
            errors.append("No links found")
        if not model.tanks:
            errors.append("No tanks defined - at least one tank required for tank optimization")
        return {"ok": len(errors) == 0, "errors": errors}

def load_yaml_or_inp(path: Path) -> Tuple[NetworkModel, Dict[str, Any]]:
    """Charge YAML ou INP minimal (INP: on ne parse pas tout, on fait checksum + placeholder model)."""
    if path.suffix.lower() in (".yml", ".yaml"):
        raw = yaml.safe_load(path.read_text(encoding="utf-8"))
        nm = NetworkModel(**raw)
        return nm, {"format": "yaml"}
    elif path.suffix.lower() == ".inp":
        # Minimal handling: compute checksum and create a placeholder model
        # Full parser EPANET should populate actual nodes/links/tanks
        checksum = sha256_of_file(path)
        # create placeholder: try to parse tanks/junctions crudely? For now return empty to force user to provide YAML if they want full behavior.
        nm = NetworkModel(nodes={}, links={}, tanks={})
        return nm, {"format": "inp", "checksum": checksum}
    else:
        raise ValueError("Unsupported network format. Provide .yml/.yaml or .inp")

# -------------------------
# Mock solver (demo) and solver interface
# -------------------------
@dataclass
class SimulationResult:
    pressures_m: Dict[str, float]
    velocities_m_s: Dict[str, float]
    min_pressure_m: float
    max_velocity_m_s: float
    metadata: Dict[str, Any]

class BaseSolver:
    def simulate(self, network: NetworkModel, H_tank_m: float, diameters: Optional[Dict[str,int]] = None) -> SimulationResult:
        raise NotImplementedError

class MockSolver(BaseSolver):
    """Simple heuristic solver to test pipeline: not for production."""
    def simulate(self, network: NetworkModel, H_tank_m: float, diameters: Optional[Dict[str,int]] = None) -> SimulationResult:
        # Heuristic: base loss = sum(lengths)*k / (mean_diameter^0.5) ; pressures = H_tank - loss - elevation
        # We'll fabricate data but keep consistent shapes.
        nodes = network.nodes or {"n1": {"elevation_m": 0.0}, "n2": {"elevation_m": 5.0}}
        links = network.links or {"p1": {"length_m": 100.0, "diameter_mm": 110}}
        # compute mean diameter
        ds = []
        total_length = 0.0
        for lid, link in links.items():
            total_length += float(link.get("length_m", 100.0))
            ds.append(link.get("diameter_mm", 110))
        mean_d = (sum(ds)/len(ds)) if ds else 110.0
        # head loss proxy
        k = 0.01
        loss = k * total_length / (mean_d/1000.0)
        pressures = {}
        velocities = {}
        p_min = float("inf")
        v_max = 0.0
        for nid, n in nodes.items():
            elev = float(n.get("elevation_m", 0.0))
            p = H_tank_m - loss - elev
            pressures[nid] = round(p, 3)
            if p < p_min:
                p_min = p
        # velocities proxy
        for lid, link in links.items():
            d = link.get("diameter_mm", 110)/1000.0
            # arbitrary Q proxy: depends on network size
            Q = 0.01
            v = Q / (3.14159*(d**2)/4)
            velocities[lid] = round(v, 3)
            if v > v_max:
                v_max = v
        return SimulationResult(pressures, velocities, p_min, v_max, {"H_tank_m": H_tank_m, "loss": loss})

# -------------------------
# Binary Search Optimizer
# -------------------------
class BinarySearchOptimizer:
    def __init__(self, network: NetworkModel, pressure_constraints: PressureConstraints,
                 diameter_db_path: Optional[Path] = None, solver: Optional[BaseSolver] = None):
        self.network = network
        self.pressure_min = pressure_constraints.min_pressure_m
        self.diameter_db_path = diameter_db_path
        self.solver = solver or MockSolver()

    def optimize_tank_height(self, H_min: float, H_max: float, tolerance: float = 0.1, max_iter: int = 60) -> Dict[str, Any]:
        low, high = float(H_min), float(H_max)
        best = None
        iter_count = 0

        # sanity check: monotonicity basic test
        sim_low = self.solver.simulate(self.network, low)
        sim_high = self.solver.simulate(self.network, high)
        if sim_high.min_pressure_m < sim_low.min_pressure_m:
            # warn: unexpected monotonicity, continue but mark non-monotonic
            monotonic = False
        else:
            monotonic = True

        while (high - low) > tolerance and iter_count < max_iter:
            mid = (low + high) / 2.0
            sim = self.solver.simulate(self.network, mid)
            p_min = sim.min_pressure_m
            # keep best feasible (lowest H that meets pressure)
            if p_min >= self.pressure_min:
                best = {"H_tank_m": mid, "sim": sim}
                high = mid
            else:
                low = mid
            iter_count += 1

        if best is None:
            # not feasible within bounds
            return {"feasible": False, "reason": "No height in bounds satisfies pressure_min", "checked": {"H_min": H_min, "H_max": H_max}, "iterations": iter_count}

        # Build result dict
        sim = best["sim"]
        result = {
            "feasible": True,
            "H_tank_m": round(best["H_tank_m"], 3),
            "min_pressure_m": sim.min_pressure_m,
            "max_velocity_m_s": sim.max_velocity_m_s,
            "pressures_m": sim.pressures_m,
            "velocities_m_s": sim.velocities_m_s,
            "iterations": iter_count,
            "meta": {"method": "binary", "solver": type(self.solver).__name__, "timestamp": datetime.utcnow().isoformat()}
        }
        return result

# -------------------------
# CLI commands
# -------------------------
@app.command("verify")
def cmd_verify(network: Path = typer.Argument(..., help="Chemin vers network .yml or .inp")):
    """V√©rifie l'int√©grit√© et la validit√© minimale du r√©seau."""
    v = NetworkValidator()
    r = v.check_integrity(network)
    if not r["ok"]:
        typer.secho("ERREUR: fichier introuvable ou illisible", fg=typer.colors.RED)
        raise typer.Exit(code=1)
    # If YAML, validate content
    if network.suffix.lower() in (".yml", ".yaml"):
        nm, meta = load_yaml_or_inp(network)
        v2 = v.validate_model(nm)
        if not v2["ok"]:
            typer.secho(f"Validation model failed: {v2['errors']}", fg=typer.colors.RED)
            raise typer.Exit(code=1)
    typer.secho(f"Integrity OK. checksum: {r['checksum']}", fg=typer.colors.GREEN)
    typer.echo(json.dumps(r, indent=2))

@app.command("simulate")
def cmd_simulate(network: Path = typer.Argument(...), H: float = typer.Option(..., help="H_tank (m)"),
                 diameters: Optional[Path] = typer.Option(None, help="Optional diameters yaml")):
    """Lance une simulation unique (H donn√©)."""
    nm, meta = load_yaml_or_inp(network)
    solver = MockSolver()
    sim = solver.simulate(nm, H, None)
    out = {
        "H_tank_m": H,
        "min_pressure_m": sim.min_pressure_m,
        "max_velocity_m_s": sim.max_velocity_m_s,
        "pressures_m": sim.pressures_m,
        "velocities_m_s": sim.velocities_m_s,
        "meta": {"solver": "MockSolver", "timestamp": datetime.utcnow().isoformat()}
    }
    typer.echo(json.dumps(out, indent=2))

@app.command("optimize")
def cmd_optimize(network: Path = typer.Argument(...),
                 config: Path = typer.Option(..., help="config.yml with optimization settings"),
                 out: Path = typer.Option(Path("results/tank_opt.json"), help="Output JSON")):
    """Optimise H_tank (m√©thode 'binary' pour l'instant)."""
    cfg_raw = yaml.safe_load(config.read_text(encoding="utf-8"))
    cfg = OptimizationConfig(**cfg_raw.get("optimization", {}))
    pc = PressureConstraints(**cfg_raw.get("pressure_constraints", {"min_pressure_m": 12.0}))
    nm, meta = load_yaml_or_inp(network)

    # basic validation
    v = NetworkValidator()
    vmodel = v.validate_model(nm)
    if not vmodel["ok"]:
        typer.secho(f"Model validation errors: {vmodel['errors']}", fg=typer.colors.RED)
        raise typer.Exit(code=1)

    if cfg.method != "binary":
        typer.secho("Pour le moment la m√©thode 'binary' est impl√©ment√©e dans ce squelette.", fg=typer.colors.YELLOW)

    # choose solver (mock for now)
    solver = MockSolver()

    optimizer = BinarySearchOptimizer(nm, pc, Path(cfg.diameter_db), solver=solver)
    # determine H bounds
    if cfg.H_fixed_m is not None:
        H_min = H_max = cfg.H_fixed_m
    elif cfg.H_bounds_m is not None:
        H_min, H_max = cfg.H_bounds_m
    else:
        typer.secho("H_bounds or H_fixed must be provided in config", fg=typer.colors.RED)
        raise typer.Exit(code=1)

    res = optimizer.optimize_tank_height(H_min, H_max, tolerance=cfg.tolerance_m, max_iter=cfg.max_iterations)
    out.parent.mkdir(parents=True, exist_ok=True)
    out.write_text(json.dumps(res, indent=2, ensure_ascii=False), encoding="utf-8")
    typer.secho(f"Optimization done. result saved to {out}", fg=typer.colors.GREEN)

@app.command("auto-optimize")
def cmd_auto(network: Path = typer.Argument(...),
             config: Path = typer.Option(...),
             out: Path = typer.Option(Path("results/tank_auto.json"))):
    """
    Pipeline complet simple: verify -> optimize -> save (binary for now).
    """
    # Verify
    v = NetworkValidator()
    r = v.check_integrity(network)
    if not r["ok"]:
        typer.secho("Integrity check failed", fg=typer.colors.RED)
        raise typer.Exit(code=1)
    # run optimize
    cmd_optimize.callback(network=network, config=config, out=out)
    # Could chain report generation here
    typer.secho("Auto optimize finished (see results).", fg=typer.colors.CYAN)

if __name__ == "__main__":
    app()
```

---

# Fichiers d‚Äôexemple (`config.yml`, `diameters.yml`)

Colle ces fichiers dans `project/config.yml` et `project/data/diameters.yml`.

`config.yml`

```yaml
optimization:
  method: "binary"
  H_bounds_m: [50.0, 80.0]
  H_fixed_m: null
  tolerance_m: 0.1
  max_iterations: 60
  diameter_db: "data/diameters.yml"

pressure_constraints:
  min_pressure_m: 12.0

solver:
  type: "mock"
```

`data/diameters.yml`

```yaml
- d_mm: 50
  cost_per_m: 3500
  roughness: 130
- d_mm: 75
  cost_per_m: 5200
  roughness: 130
- d_mm: 110
  cost_per_m: 9800
  roughness: 130
- d_mm: 160
  cost_per_m: 15000
  roughness: 130
```

---

# Comment tester localement (rapide)

1. Placer `tank_cli.py` dans `src/lcpi/plugins/aep/`.
    
2. Installer d√©pendances : `pip install typer pydantic pyyaml`
    
3. Cr√©er `project/network.yml` minimal (exemple ci-dessous).
    
4. Cr√©er `project/config.yml` et `project/data/diameters.yml` (cf. ci-dessus).
    
5. Lancer :
    
    - `python tank_cli.py verify project/network.yml`
        
    - `python tank_cli.py simulate project/network.yml --H 65`
        
    - `python tank_cli.py optimize project/network.yml --config project/config.yml --out results/opt.json`
        
    - `python tank_cli.py auto-optimize project/network.yml --config project/config.yml --out results/auto.json`
        

Exemple minimal `project/network.yml` :

```yaml
nodes:
  node_001:
    elevation_m: 10
  node_002:
    elevation_m: 8
links:
  pipe_1:
    from: node_001
    to: node_002
    length_m: 150
    diameter_mm: 110
tanks:
  tank_A:
    radier_elevation_m: 70.0
    init_level_m: 2.0
```

---

# Points d‚Äôattention / recommandations (court)

- **Remplacer `MockSolver`** par `EPANETOptimizer` avant d‚Äôutiliser sur des r√©seaux r√©els. Le wrapper EPANET doit √©crire le `.inp` temporaire, modifier `[TANKS]` et `[PIPES]`, lancer EPANET et lire r√©sultats.
    
- **Valider monotonicit√©** avant binary (je l‚Äôai montr√© dans le squelette).
    
- **Stocker les r√©sultats sign√©s** avec ton `integrity_manager` (√† int√©grer dans le controller apr√®s chaque `out.write_text`).
    
- **Adapter noms de commandes** si conflits existants (ajouter suffixe `-aep` si n√©cessaire).
    
- **Tests** : je peux g√©n√©rer tests pytest pour la search binaire et le mock solver si tu veux.
    
- **Integration with report** : le JSON de sortie a les champs n√©cessaires (`report_payload.template`, `placeholders`) ‚Äî `lcpi rapport` pourra le consommer.
    

---

Super ‚Äî je garde ton plan comme base et je le rends **pratique, impl√©mentable et orient√© r√©sultat** : l‚Äôalgorithme ira lire la base de prix DN (SQLite/YAML) existante, testera des combinaisons H_tank + diam√®tres, et produira **deux propositions** claires (au choix) :

- **Proposition A ‚Äî "Budget max"** : co√ªt CAPEX minimal qui respecte toutes les contraintes hydrauliques.
    
- **Proposition B ‚Äî "Robuste / √âconome"** : compromis CAPEX‚ÜîOPEX (ex. point ¬´ knee ¬ª du front de Pareto ou minimisation de `CAPEX + Œª¬∑OPEX_NPV`).
    

Je te donne : 1) architecture technique & acc√®s DB ; 2) algorithme concret (workflow + pseudocode) ; 3) m√©thodes d‚Äôoptimisation am√©lior√©es (nested‚Üíseed‚ÜíGA, surrogate loop) ; 4) comment choisir les 2 propositions depuis le Pareto ; 5) API & CLI ; 6) tests & indicateurs ; 7) contenu min. des fichiers. Tout pr√™t √† impl√©menter.

# 1 ‚Äî Architecture technique (r√©sum√© rapide)

- **DB diam√®tres** (pr√©f√©rence : SQLite `diameters` table dans DB globale AEP).
    
- **Modules** (√† ajouter/adapter) : `optimizer/scoring.py`, `optimizer/db.py`, `optimizer/controllers.py`, `optimizer/algorithms/*`, `optimizer/cache.py`.
    
- **Solveurs** : `epanet_optimizer` et `lcpi_optimizer` (API identique).
    
- **Cache** : hash(network, H_tank, diam_vector) ‚Üí SimulationResult.
    
- **Orchestrateur** : un contr√¥leur unique `TankOptimizerController` qui ex√©cute pipeline et retourne JSON standardis√©.
    
- **Sortie** : JSON + sim files + entr√©e au `lcpi rapport`.
    

# 2 ‚Äî Sch√©ma DB minimal pour diam√®tres (SQLite)

Utilise la DB globale AEP ‚Äî table `diameters` :

```sql
CREATE TABLE diameters (
  id INTEGER PRIMARY KEY,
  d_mm INTEGER NOT NULL,
  material TEXT,
  cost_per_m REAL NOT NULL,   -- en XOF
  roughness REAL,             -- Hazen-Williams / coeff
  eta_indicator TEXT,         -- usage (distribution, branchement...)
  available BOOLEAN DEFAULT 1,
  stock INTEGER DEFAULT NULL
);

CREATE INDEX idx_diam_dmm ON diameters(d_mm);
CREATE INDEX idx_diam_available ON diameters(available);
```

API simple (Python sqlite3 or SQLAlchemy):

```py
def get_candidate_diameters(min_d, max_d, material=None):
    q = "SELECT d_mm, cost_per_m, roughness FROM diameters WHERE available=1 AND d_mm BETWEEN ? AND ? ORDER BY d_mm"
```

# 3 ‚Äî Principes d‚Äôoptimisation et choix des 2 propositions

- **Espace de d√©cision** = `H_tank` (continu ou discret) + vecteur `D` (diam√®tre par tron√ßon ‚Äî choix discret depuis DB).
    
- **Contraintes (hard)** : `pressure_min` au(x) n≈ìud(s), `v_min/v_max` sur liens, pompe feasible, budget (optionnel).
    
- **Objectifs** :
    
    - CAPEX = Œ£(length_link √ó cost_per_m(d_link))
        
    - OPEX_NPV = actualisation sur horizon T (via √©nergie de pompage calcul√©e par le solveur)
        
    - Score unique possible : `J = CAPEX + Œª * OPEX_NPV` (Œª configurable)
        
- **S√©lection des deux propositions** :
    
    - Ex√©cuter optimisation **multi-objectif** (NSGA-II/GA) ‚Üí obtenir front de Pareto `{(CAPEX_i, OPEX_i, feas_i)}`.
        
    - **Proposition A** = point faisable du front avec **CAPEX minimal** (si plusieurs, choisir celui avec meilleur OPEX).
        
    - **Proposition B** = **knee point** du front (maximal ¬´ gain marginal ¬ª en OPEX par unit√© CAPEX) ou minimisation de `J` avec Œª choisi.
        
    - Si pas de front (m√©thode greedy/nested), produire 2 solutions : (i) greedy min-CAPEX, (ii) solution J-minimale si search permet.
        

# 4 ‚Äî Pipeline algorithmique concret (haut niveau)

1. **Pr√©-checks** : validit√© r√©seau, int√©grit√© fichier, diam√®tres disponibles, v√©rification H_bounds r√©alisable (simulate H_max once).
    
2. **Phase 0 ‚Äî Seed** : produire un ou plusieurs seeds :
    
    - solution actuelle (si diam existants),
        
    - nested greedy result (rapide),
        
    - quelques heuristics (monter diam uniquement sur tron√ßons critiques).
        
3. **Phase 1 ‚Äî Nested greedy (rapide)** :
    
    - binary search H ‚Üí obtenir H0 (satisfaisant) avec diameters initiales (ex. current).
        
    - pour H0, parcourir liens class√©s par criticit√© (impact sur p_min / longueur) et r√©duire progressivement diam√®tre au plus petit qui respecte `vmax` et `pmin`. Retour : Sol_greedy.
        
    - Stocker sol_greedy.
        
4. **Phase 2 ‚Äî Global / NSGA (si demand√© ou r√©seau petit/moyen)** :
    
    - initialiser population avec : sol_greedy, solution actuelle, random perturbations.
        
    - inclure `H_tank` comme g√®ne additionnel.
        
    - fitness = vector (CAPEX, OPEX_NPV) ; contraintes g√©r√©es par p√©nalit√©s fortes (ou reject).
        
    - ex√©cuter NSGA/GA parallel, cache/checkpoint.
        
    - extraire Pareto front.
        
5. **Phase 3 ‚Äî Surrogate (si r√©seau grand ou budget sims limit√©)** :
    
    - √©chantillonner LHS n points (H, D sample) ‚Üí simuler (parall√®le).
        
    - entra√Æner XGBoost pour pr√©dire `min_pressure` et `CAPEX`, `OPEX_est`.
        
    - optimiser sur surrogate pour g√©n√©rer K candidats ‚Üí valider top-K sur solveur.
        
    - boucle active-learning : ajouter validated points et r√©entra√Æner si n√©cessaire.
        
6. **Phase 4 ‚Äî S√©lection & Raffinement local** :
    
    - √† partir du front ou des candidats, s√©lectionner top candidates (ex: 20), r√©aliser petits hill-climb locaux (swap diam√®tre ¬±1 step) pour am√©liorer contrainte/co√ªt.
        
7. **Phase 5 ‚Äî Choix final des 2 propositions** : extraire MIN_CAPEX feasible & KNEE (ou J-min selon option).
    
8. **Phase 6 ‚Äî Reporting** : sim final complet, JSON + sim files, signer log, exporter template for `lcpi rapport`.
    

# 5 ‚Äî Pseudocode (concret, int√©grable)

```py
def optimize_network(network, config):
    validator.check(network)
    seed = nested_greedy(network, config)   # rapide
    if config.method == "nested":
        sols = [seed]
    elif config.method == "global":
        pop = init_population(seed, config)
        pareto = run_nsga(pop, network, config)
        sols = pareto
    elif config.method == "surrogate":
        ds = sample_lhs(network, config.n_initial)
        train_surrogate(ds)
        candidates = optimize_surrogate(n_cand=1000)
        sols = validate_topk(candidates, k=20)
        sols += [seed]
    # refine top sols
    top = select_top(sols, k=20)
    refined = [local_refine(s, network, config) for s in top]
    all_sols = merge(sols, refined)
    pareto = compute_pareto(all_sols)
    # pick results
    solA = pick_min_capex(pareto)
    solB = pick_knee_point(pareto) or pick_min_J(all_sols, lambda=config.lambda_)
    return {"capex_min": solA, "balanced": solB, "pareto": pareto}
```

# 6 ‚Äî D√©tails d‚Äôimpl√©mentation importants

### 6.1 ‚Äî Criticit√© lien / tri dans nested greedy

- Crit√®re = `impact = length * (downstream_count + pressure_sensitivity)` (approx).
    
- Priorit√© aux tron√ßons longs et sur le chemin vers nodal critique.
    

### 6.2 ‚Äî Repr√©sentation diam√©trique compacte

- Repr√©senter diam√®tre comme index dans sorted list `D_list`. Swap/mutate = ¬±k index.
    
- Permet mutations discr√®tes simples et arrondir facilement.
    

### 6.3 ‚Äî P√©nalit√©s & contraintes

- Strong penalty for infeasible: `score = CAPEX + Œª*OPEX + PEN*(sum_violation^2)`, with PEN large (e.g. 1e9) to force feasibility.
    
- Alternative: reject infeasible in GA (makes search harder).
    

### 6.4 ‚Äî Parall√©lisation & caching

- Use `ProcessPoolExecutor` to evaluate population members; cache results on disk keyed by SHA256 of (network_hash + H + diam_vector).
    
- Implement checkpointing: save population every N generations to disk.
    

### 6.5 ‚Äî Stop criteria

- Convergence of Pareto (no improvement over Ggens), or max evaluations, or wall timeout.
    

# 7 ‚Äî Choix des 2 propositions depuis un front

- **Compute Pareto front** (non-dominated).
    
- **Pick A (Budget)**: argmin CAPEX among feasible.
    
- **Pick B (Robuste)**: find knee point: for sorted Pareto by CAPEX, compute distance to utopia point (min CAPEX, min OPEX) or compute maximal curvature / elbow. Algorithm: normalize (CAPEX,OPEX) to [0,1], compute second derivative or max perpendicular distance to line joining extremes. Choose that.
    
- Fallback: minimize `J = CAPEX + Œª¬∑OPEX` for chosen Œª.
    

# 8 ‚Äî API & CLI (options recommand√©es)

CLI example:

```
lcpi aep tank optimize network.inp \
  --method global \
  --objective multi \
  --lambda 0.2 \
  --solver epanet \
  --budget 1200000 \
  --pareto --export results/pareto.json \
  --select "capex_min,knee"  # returns two proposals
```

Parameters to support:

- `--method` (nested|global|surrogate|binary)
    
- `--objective` (price|multi)
    
- `--lambda`
    
- `--budget`
    
- `--pareto` + `--export`
    
- `--select` (which proposals: capex_min, knee, min_J)
    
- `--max-evals`, `--workers`, `--seed`
    

# 9 ‚Äî Tests & m√©triques √† tracker

- **Unit tests** : scoring CAPEX compute, DB price lookup, greedy selection, knee detection.
    
- **Integration tests** : full pipeline on small EPANET examples (expected outputs).
    
- **Benchmarks** : #evals, time per evaluation, cache hit rate.
    
- **Quality metrics** : % constraints satisfied, CAPEX reduction vs baseline, energy saving %.
    
- **CI** : add a job that runs nested on a tiny test network.
    

# 10 ‚Äî Format de sortie (r√©sum√©)

- JSON with fields : `meta`, `proposals` [{id,label,CAPEX,OPEX, H_tank, diameters, pressures,velocities,violations,sim_file}], `pareto` list. Include `report_payload` for `lcpi rapport`.
    

# 11 ‚Äî Contenu minimal requis dans INP / YAML pour que l‚Äôalgorithme fonctionne

- **N≈ìuds** : id, √©l√©vation (`elevation_m`), demandes de base (m3/s ou m3/h), patterns optionnels.
    
- **Tuyaux** : id, node1,node2,length_m, diameter_mm (current), roughness/coeff.
    
- **R√©servoir/TANK** : id, radier_elevation_m (cote radier), init_level, min/max levels.
    
- **Pompes** : courbes ou head/Q ou param√®tres.
    
- **Unit√©/metadata** : unit√© de d√©bit, syst√®me coordonn√©es.
    
- **(Optionnel mais recommand√©)** : existing diameter recommended to seed optim; material tags.
    

# 12 ‚Äî Bonnes pratiques & recommandations

- **Stocker diam DB en SQLite** (plus rapide, filtrable); YAML ok en dev.
    
- **Commencer par nested greedy** pour produire seed rapide.
    
- **Si r√©seau > 500 links ‚Üí surrogate** comme premi√®re approche.
    
- **Toujours valider final top solutions sur EPANET**.
    
- **Journaliser & signer** (ton module d‚Äôint√©grit√©) chaque run.
    
- **Exporter CSV/Excel BOM** des diam√®tres choisis et m√©tr√©s.
    

---

## Vision g√©n√©rale
Objectif: ajouter l‚Äôoptimisation des r√©servoirs sur√©lev√©s en r√©utilisant l‚Äôexistant, sans r√©gression, avec une int√©gration CLI/rapports propre et des algorithmes progressifs (binary ‚Üí nested ‚Üí global ‚Üí surrogate).

### Jalon 1 ‚Äî Architecture minimale op√©rationnelle (MVP Binary)
- **Cibles**
  - Structure `optimizer/` ajout√©e sans toucher √† `optimization/` existant.
  - CLI d√©di√©e `lcpi aep tank` (verify, simulate, optimize, auto-optimize).
  - Impl√©mentation fonctionnelle `BinarySearchOptimizer` avec `MockSolver`.
  - I/O minimal YAML/INP + validateurs d‚Äôint√©grit√©.
  - Base diam√®tres en YAML et format JSON de sortie standardis√©.
- **Livrables**
  - Dossiers: `src/lcpi/aep/optimizer/{controllers.py, algorithms/binary.py, validators.py, io.py, scoring.py(stub)}`.
  - CLI: `lcpi aep tank verify|simulate|optimize|auto-optimize`.
  - Fichiers d‚Äôexemple: `project/config.yml`, `project/data/diameters.yml`, `project/network.yml`.
  - Tests: unitaires binary (convergence, bornes).
- **Crit√®res d‚Äôacceptation**
  - `lcpi aep tank verify` et `optimize --method binary` passent sur r√©seau de test.
  - Sortie JSON conforme (meta, r√©sultats hydro, placeholders rapport).
  - Aucune r√©gression sur `lcpi aep network-optimize-unified`.
- **Risques/D√©pendances**
  - INP non pars√© finement (placeholder accept√©). Remplac√© √† Jalon 2 via EPANET wrapper.

### Jalon 2 ‚Äî Algorithmes √©tendus + Wrappers solveurs
- **Cibles**
  - `NestedGreedyOptimizer` (H_tank via binary, puis diam√®tres glouton).
  - `GlobalOptimizer` (wrapper `GeneticOptimizer`) avec g√®ne `H_tank`.
  - Wrappers solveurs: `EPANETOptimizer` (modif .inp, extraction r√©sultats) et `LCPIOptimizer`.
  - Scoring CAPEX/OPEX et cache simple (en m√©moire).
- **Livrables**
  - `src/lcpi/aep/optimizer/algorithms/{nested.py, global_opt.py}`.
  - `src/lcpi/aep/optimizer/solvers/{epanet_optimizer.py, lcpi_optimizer.py}`.
  - `src/lcpi/aep/optimizer/scoring.py` (CAPEX, OPEX basique).
  - `src/lcpi/aep/optimizer/cache.py` (LRU simple).
  - Tests: nested (faisabilit√©/co√ªt), global wrapper (int√©gration petite instance).
- **Crit√®res d‚Äôacceptation**
  - `--method nested` et `--method global` op√©rationnels avec EPANET.
  - Respect contraintes pression/vitesse; calcul CAPEX coh√©rent avec DB diam√®tres.
  - Backward compatibility confirm√©e (anciens projets/commandes).
- **Risques/D√©pendances**
  - Stabilit√© EPANET/wntr et temps de simulation; pr√©voir timeouts/logging.

### Jalon 3 ‚Äî Surrogate/IA + Performance et Fiabilit√©
- **Cibles**
  - `SurrogateOptimizer` (LHS, XGBoost/RandomForest, optimisation sur mod√®le, validation top‚ÄëK).
  - Cache intelligent (hash param√®tres, persistance disque).
  - Parall√©lisation (ProcessPool) + checkpointing simple.
  - M√©triques: temps/simulation, taux de cache-hit, convergence.
- **Livrables**
  - `src/lcpi/aep/optimizer/algorithms/surrogate.py`.
  - Cache persistant dans `optimizer/cache.py` (hash SHA256 de network+H+diam).
  - Benchmarks et tests de performance/qualit√© (√©cart surrogate vs solveur r√©el).
- **Crit√®res d‚Äôacceptation**
  - Acc√©l√©ration mesur√©e vs nested/global (x‚â•3 sur cas test).
  - √âcart max admis sur pressions/couts valid√©s (p.ex. ‚â§5% sur top‚ÄëK).
  - Robustesse: reprise apr√®s interruption, logs d√©taill√©s, retries.
- **Risques/D√©pendances**
  - Qualit√© des features/dataset; calibrage du n_samples et du top‚ÄëK.

### Jalon 4 ‚Äî Int√©gration compl√®te CLI/Rapports + QA et Docs
- **Cibles**
  - Int√©gration aux sous-commandes existantes: `lcpi aep tank` ajout√© proprement.
  - Gabarit rapport `optimisation_tank.jinja2` + payload pr√™t pour `lcpi rapport`.
  - S√©curit√©/int√©grit√©: SHA256, journalisation, non-r√©gression compl√®te.
  - Documentation et exemples; gestion d‚Äôerreurs UX (messages clairs).
- **Livrables**
  - `src/lcpi/aep/commands/main.py` mis √† jour (ajout sous‚Äëcommande `tank`).
  - Template rapport + exemples d‚Äôexports JSON/CSV diam√®tres.
  - Suite de tests d‚Äôint√©gration E2E, tests de compatibilit√©.
  - Documentation utilisateur et README d‚Äôarchitecture.
- **Crit√®res d‚Äôacceptation**
  - Toutes les commandes `lcpi aep tank` fonctionnent avec EPANET/LCPI.
  - G√©n√©ration de rapport √† partir de la sortie JSON.
  - Tests verts (unitaires, int√©gration, compatibilit√©) sur CI locale.
- **Risques/D√©pendances**
  - Collisions CLI; veiller au nommage coh√©rent et √† la r√©tro‚Äëcompatibilit√©.

Notes d‚Äôorganisation
- Prioriser la r√©utilisation: `GeneticOptimizer`, `ConstraintManager`, `SolverFactory`, syst√®me de rapports et validation existants.
- Garder les interfaces stables; encapsuler nouveaut√©s dans `optimizer/`.
- Mesurer en continu: temps de simulation, taux de cache, respect contraintes, r√©gressions.