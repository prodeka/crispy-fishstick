[pytest]
pythonpath = src
testpaths = tests
addopts = -q -m "not obsolete"
markers =
    obsolete: mark test as obsolete (skipped by default)
    integration: marks tests as integration tests
    asyncio: marks asyncio-based tests
    robustesse: marks robustness tests
    jalon1: marks jalon1 tests
    jalon2: marks jalon2 tests
    performance: marks performance tests
[tool:pytest]
# Configuration pytest pour LCPI-CLI

# Répertoires de test
testpaths = tests

# Fichiers de test
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Options de découverte
addopts = 
    # Verbosité et rapport
    -v
    --tb=short
    --strict-markers
    --strict-config
    --disable-warnings
    -W ignore::UserWarning:wntr.*
    -W ignore::DeprecationWarning:wntr.*
    -W ignore::UserWarning:pkg_resources.*
    -W ignore::DeprecationWarning:pkg_resources.*
    
    # Couverture de code
    --cov=src/lcpi
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-fail-under=70
    
    # Tests parallèles
    -n auto
    --dist=loadfile
    
    # Marqueurs
    --markers=slow:marks tests as slow (deselect with '-m "not slow"')'
    --markers=integration:marks tests as integration tests'
    --markers=unit:marks tests as unit tests'
    --markers=smoke:marks tests as smoke tests'
    
    # Filtres
    --ignore=venv
    --ignore=.venv
    --ignore=env
    --ignore=__pycache__
    --ignore=.pytest_cache
    --ignore=build
    --ignore=dist
    
    # Timeout
    --timeout=300
    --timeout-method=thread

# Configuration des marqueurs
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    integration: marks tests as integration tests
    unit: marks tests as unit tests
    smoke: marks tests as smoke tests
    aep: marks tests as AEP module tests
    cm: marks tests as CM module tests
    bois: marks tests as BOIS module tests
    beton: marks tests as BETON module tests
    hydro: marks tests as HYDRO module tests
    cli: marks tests as CLI tests
    api: marks tests as API tests
    database: marks tests as database tests
    network: marks tests as network tests
    optimization: marks tests as optimization tests
    reporting: marks tests as reporting tests
    logging: marks tests as logging tests
    project: marks tests as project management tests
    sandbox: marks tests as sandbox tests

# Configuration de la couverture
[tool:pytest.ini_options]
addopts = 
    --cov=src
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-fail-under=80

# Configuration des filtres de couverture
[tool:coverage.run]
source = src
omit = 
    */tests/*
    */test_*
    */__pycache__/*
    */venv/*
    */.venv/*
    */env/*
    */build/*
    */dist/*
    */setup.py
    */conftest.py

# Configuration des rapports de couverture
[tool:coverage.report]
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod

# Configuration des rapports HTML
[tool:coverage.html]
directory = htmlcov
title = LCPI-CLI Coverage Report

# Configuration des rapports XML
[tool:coverage.xml]
output = coverage.xml

# Configuration des tests parallèles
[tool:pytest-xdist]
addopts = -n auto --dist=loadfile

# Configuration des timeouts
[tool:pytest-timeout]
timeout = 300
timeout_method = thread

# Configuration des marqueurs personnalisés
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    integration: marks tests as integration tests
    unit: marks tests as unit tests
    smoke: marks tests as smoke tests
    aep: marks tests as AEP module tests
    cm: marks tests as CM module tests
    bois: marks tests as BOIS module tests
    beton: marks tests as BETON module tests
    hydro: marks tests as HYDRO module tests
    cli: marks tests as CLI tests
    api: marks tests as API tests
    database: marks tests as database tests
    network: marks tests as network tests
    optimization: marks tests as optimization tests
    reporting: marks tests as reporting tests
    logging: marks tests as logging tests
    project: marks tests as project management tests
    sandbox: marks tests as sandbox tests 