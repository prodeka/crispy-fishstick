#!/usr/bin/env python3
"""
Test de l'adaptateur de rapport V11.
"""

import sys
import json
import tempfile
from pathlib import Path

sys.path.insert(0, 'src')

def test_v11_report_adapter():
    """Test complet de l'adaptateur de rapport V11."""
    print("üß™ Test de l'Adaptateur de Rapport V11")
    print("=" * 40)
    
    try:
        from lcpi.aep.optimizer.report_adapter import V11ReportAdapter
        from lcpi.aep.optimizer.models import OptimizationResult, Proposal, TankDecision
        
        # 1. Cr√©er un r√©sultat V11 de test
        tank = TankDecision(id="TANK1", H_m=65.0)
        proposal = Proposal(
            name="test_solution",
            is_feasible=True,
            tanks=[tank],
            diameters_mm={"PIPE1": 200, "PIPE2": 150},
            costs={"CAPEX": 150000, "OPEX_annual": 5000, "OPEX_npv": 45000},
            metrics={"min_pressure_m": 12.5, "max_velocity_m_s": 1.8}
        )
        
        result = OptimizationResult(
            proposals=[proposal],
            pareto_front=None,
            metadata={
                "method": "nested_greedy",
                "network_file": "test_network.inp",
                "algorithm": "NestedGreedy",
                "iterations": 25,
                "pressure_min_m": 10.0
            }
        )
        
        print("‚úÖ R√©sultat V11 de test cr√©√©")
        
        # 2. Cr√©er l'adaptateur
        adapter = V11ReportAdapter()
        
        # 3. M√©tadonn√©es d'ex√©cution
        execution_metadata = {
            "execution_time": "00:02:15",
            "lambda_opex": 15.0,
            "command": "price-optimize"
        }
        
        # 4. Convertir en format de log
        log_format = adapter.convert_v11_to_log_format(result, execution_metadata)
        
        print("‚úÖ Conversion V11 ‚Üí Log r√©ussie")
        print(f"   ID: {log_format['id']}")
        print(f"   Titre: {log_format['titre_calcul']}")
        print(f"   Plugin: {log_format['plugin']}")
        
        # 5. V√©rifier les champs requis
        required_fields = [
            'id', 'titre_calcul', 'timestamp', 'commande_executee',
            'donnees_resultat', 'transparence_mathematique', 'plugin', 'command'
        ]
        
        missing_fields = [field for field in required_fields if field not in log_format]
        if missing_fields:
            print(f"‚ùå Champs manquants: {missing_fields}")
            return False
        
        print("‚úÖ Tous les champs requis sont pr√©sents")
        
        # 6. V√©rifier le contenu de la transparence math√©matique
        transparence = log_format['transparence_mathematique']
        print(f"‚úÖ Transparence math√©matique ({len(transparence)} √©tapes):")
        for i, step in enumerate(transparence[:3], 1):  # Afficher les 3 premi√®res
            print(f"   {i}. {step}")
        if len(transparence) > 3:
            print(f"   ... et {len(transparence) - 3} autres √©tapes")
        
        # 7. Test de sauvegarde
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as temp_file:
            temp_path = Path(temp_file.name)
        
        log_id = adapter.save_v11_result_as_log(result, temp_path, execution_metadata)
        
        if temp_path.exists():
            print(f"‚úÖ Sauvegarde r√©ussie: {temp_path}")
            print(f"   Log ID: {log_id}")
            
            # V√©rifier le contenu sauvegard√©
            with open(temp_path, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
            
            if saved_data['id'] == log_id:
                print("‚úÖ Contenu sauvegard√© v√©rifi√©")
            else:
                print("‚ùå Probl√®me avec le contenu sauvegard√©")
                return False
            
            # Nettoyer
            temp_path.unlink()
        else:
            print("‚ùå √âchec de la sauvegarde")
            return False
        
        # 8. Test du contexte hybride
        v11_data = adapter.formatter.format_v11(result)
        hybrid_context = adapter.create_hybrid_template_context(v11_data)
        
        expected_keys = ['logs_selectionnes', 'proposals', 'metadata', 'format_type']
        missing_keys = [key for key in expected_keys if key not in hybrid_context]
        
        if missing_keys:
            print(f"‚ùå Cl√©s manquantes dans le contexte hybride: {missing_keys}")
            return False
        
        print("‚úÖ Contexte hybride cr√©√© avec succ√®s")
        print(f"   Format type: {hybrid_context['format_type']}")
        print(f"   Is V11: {hybrid_context['is_v11_format']}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors du test de l'adaptateur: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_adapter_integration_with_reporting():
    """Test l'int√©gration avec le syst√®me de rapport existant."""
    print("\nüß™ Test d'int√©gration avec le syst√®me de rapport")
    print("=" * 50)
    
    try:
        from lcpi.aep.optimizer.report_adapter import create_log_from_v11_result
        from lcpi.aep.optimizer.models import OptimizationResult, Proposal, TankDecision
        
        # Cr√©er un r√©sultat de test
        tank = TankDecision(id="TANK1", H_m=70.0)
        proposal = Proposal(
            name="integration_test",
            is_feasible=True,
            tanks=[tank],
            diameters_mm={"PIPE1": 250},
            costs={"CAPEX": 200000, "OPEX_npv": 60000},
            metrics={"min_pressure_m": 15.0}
        )
        
        result = OptimizationResult(
            proposals=[proposal],
            pareto_front=None,
            metadata={
                "method": "global_optimization",
                "network_file": "integration_test.inp",
                "algorithm": "NSGA-II",
                "population_size": 50,
                "generations": 100
            }
        )
        
        # Test de la fonction utilitaire
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as temp_file:
            temp_path = Path(temp_file.name)
        
        execution_metadata = {
            "execution_time": "00:10:30",
            "lambda_opex": 20.0
        }
        
        log_id = create_log_from_v11_result(result, temp_path, execution_metadata)
        
        print("‚úÖ Fonction utilitaire test√©e avec succ√®s")
        print(f"   Log ID: {log_id}")
        print(f"   Fichier: {temp_path}")
        
        # V√©rifier que le fichier peut √™tre lu par le syst√®me de rapport
        if temp_path.exists():
            with open(temp_path, 'r', encoding='utf-8') as f:
                log_data = json.load(f)
            
            # V√©rifier la structure pour compatibilit√© avec lcpi rapport
            if ('titre_calcul' in log_data and 
                'donnees_resultat' in log_data and 
                'transparence_mathematique' in log_data):
                print("‚úÖ Structure compatible avec 'lcpi rapport'")
            else:
                print("‚ùå Structure incompatible")
                return False
            
            # Nettoyer
            temp_path.unlink()
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors du test d'int√©gration: {e}")
        return False

def main():
    """Fonction principale."""
    print("üîß Test de l'Adaptateur de Rapport V11")
    print("V√©rification de la compatibilit√© avec 'lcpi rapport'")
    print("=" * 60)
    
    tests = [
        ("Adaptateur V11", test_v11_report_adapter),
        ("Int√©gration Rapport", test_adapter_integration_with_reporting)
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"\nüî¨ Test: {test_name}")
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"üí• Erreur critique dans {test_name}: {e}")
            results.append((test_name, False))
    
    # R√©sum√© final
    print("\n" + "=" * 60)
    print("üìä R√âSUM√â DES TESTS")
    print("=" * 60)
    
    total_tests = len(results)
    passed_tests = sum(1 for _, result in results if result)
    
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"   {status} - {test_name}")
    
    print(f"\nüéØ R√©sultat global: {passed_tests}/{total_tests} tests r√©ussis")
    
    if passed_tests == total_tests:
        print("üéâ Adaptateur fonctionnel ! Compatibilit√© V11 ‚Üî 'lcpi rapport' assur√©e.")
        print("üí° L'adaptateur peut √™tre utilis√© pour int√©grer les r√©sultats V11.")
    else:
        print("‚ö†Ô∏è  Probl√®mes d√©tect√©s dans l'adaptateur.")
    
    return passed_tests == total_tests

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
