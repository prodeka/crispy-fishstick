#!/usr/bin/env python3
"""
Test de g√©n√©ration de rapports global avec Pandoc
"""

import sys
import os
import tempfile
import shutil
from pathlib import Path

# Ajouter le chemin pour importer les modules
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def test_report_generation():
    """Test de la g√©n√©ration de rapports avec Pandoc"""
    print("üîµ TEST G√âN√âRATION DE RAPPORTS")
    print("=" * 60)
    print("Ce test v√©rifie la g√©n√©ration de rapports avec Pandoc.")
    print("=" * 60)
    
    try:
        from lcpi.reporter import GlobalReportBuilder
        
        # Cr√©er un r√©pertoire temporaire pour le test
        with tempfile.TemporaryDirectory() as temp_dir:
            test_project_dir = Path(temp_dir) / "test_project"
            test_project_dir.mkdir()
            
            # Cr√©er des fichiers de test pour simuler un projet
            (test_project_dir / "config.yml").write_text("""
plugins:
  - aep
  - cm
  - bois
name: "Projet Test LCPI"
description: "Projet de test pour la g√©n√©ration de rapports"
""")
            
            # Cr√©er des fichiers de donn√©es pour chaque plugin
            (test_project_dir / "data" / "aep").mkdir(parents=True)
            (test_project_dir / "data" / "aep" / "population_data.yml").write_text("""
population_base: 1000
taux_croissance: 0.037
annees: 20
""")
            
            (test_project_dir / "data" / "cm").mkdir(parents=True)
            (test_project_dir / "data" / "cm" / "beam_data.yml").write_text("""
beam_length: 6.0
beam_height: 0.3
beam_width: 0.2
""")
            
            (test_project_dir / "data" / "bois").mkdir(parents=True)
            (test_project_dir / "data" / "bois" / "wood_data.yml").write_text("""
wood_type: "Douglas"
section: "200x400"
length: 4.5
""")
            
            # Initialiser le g√©n√©rateur de rapports
            builder = GlobalReportBuilder(str(test_project_dir))
            
            print(f"‚úÖ G√©n√©rateur de rapports initialis√©")
            print(f"   Projet: {test_project_dir}")
            print(f"   Pandoc disponible: {builder.pandoc_available}")
            
            if not builder.pandoc_available:
                print("‚ö†Ô∏è Pandoc n'est pas disponible, test limit√©")
                return True
            
            # Analyser le projet
            project_data = builder.analyze_project()
            
            print(f"‚úÖ Projet analys√©")
            print(f"   Plugins d√©tect√©s: {project_data['metadata']['plugins']}")
            print(f"   R√©sultats: {len(project_data['results'])} plugins")
            
            # Test de g√©n√©ration HTML
            try:
                html_report = builder.generate_report("html")
                print(f"‚úÖ Rapport HTML g√©n√©r√©: {html_report}")
                
                # V√©rifier que le fichier existe
                if Path(html_report).exists():
                    print(f"   ‚úÖ Fichier cr√©√©: {Path(html_report).stat().st_size} bytes")
                else:
                    print(f"   ‚ùå Fichier non trouv√©")
                    return False
                    
            except Exception as e:
                print(f"‚ùå Erreur g√©n√©ration HTML: {e}")
                return False
            
            # Test de g√©n√©ration JSON
            try:
                json_report = builder.generate_report("json")
                print(f"‚úÖ Rapport JSON g√©n√©r√©: {json_report}")
                
                # V√©rifier que le fichier existe
                if Path(json_report).exists():
                    print(f"   ‚úÖ Fichier cr√©√©: {Path(json_report).stat().st_size} bytes")
                else:
                    print(f"   ‚ùå Fichier non trouv√©")
                    return False
                    
            except Exception as e:
                print(f"‚ùå Erreur g√©n√©ration JSON: {e}")
                return False
            
            # Test de g√©n√©ration Markdown
            try:
                md_report = builder.generate_report("markdown")
                print(f"‚úÖ Rapport Markdown g√©n√©r√©: {md_report}")
                
                # V√©rifier que le fichier existe
                if Path(md_report).exists():
                    print(f"   ‚úÖ Fichier cr√©√©: {Path(md_report).stat().st_size} bytes")
                else:
                    print(f"   ‚ùå Fichier non trouv√©")
                    return False
                    
            except Exception as e:
                print(f"‚ùå Erreur g√©n√©ration Markdown: {e}")
                return False
            
            print(f"\n‚úÖ Tous les tests de g√©n√©ration r√©ussis !")
            return True
            
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return False

def test_report_with_real_data():
    """Test avec des donn√©es r√©elles du projet actuel"""
    print(f"\nüîµ TEST AVEC DONN√âES R√âELLES")
    print("-" * 40)
    
    try:
        from lcpi.reporter import GlobalReportBuilder
        
        # Utiliser le r√©pertoire actuel
        current_dir = Path.cwd()
        
        # Initialiser le g√©n√©rateur
        builder = GlobalReportBuilder(str(current_dir))
        
        print(f"‚úÖ G√©n√©rateur initialis√© pour: {current_dir}")
        print(f"   Pandoc disponible: {builder.pandoc_available}")
        
        if not builder.pandoc_available:
            print("‚ö†Ô∏è Pandoc non disponible, test limit√©")
            return True
        
        # Analyser le projet r√©el
        project_data = builder.analyze_project()
        
        print(f"‚úÖ Projet analys√©")
        print(f"   Nom: {project_data['metadata']['name']}")
        print(f"   Plugins: {project_data['metadata']['plugins']}")
        print(f"   R√©sultats: {len(project_data['results'])} plugins")
        
        # Afficher les d√©tails des r√©sultats
        for plugin, results in project_data['results'].items():
            print(f"   üìä {plugin.upper()}: {len(results.get('files', []))} fichiers")
        
        # G√©n√©rer un rapport HTML
        try:
            html_report = builder.generate_report("html")
            print(f"‚úÖ Rapport HTML g√©n√©r√©: {html_report}")
            
            # V√©rifier le contenu
            if Path(html_report).exists():
                content = Path(html_report).read_text(encoding='utf-8')
                if "Rapport de Projet LCPI" in content:
                    print(f"   ‚úÖ Contenu valide")
                else:
                    print(f"   ‚ö†Ô∏è Contenu inattendu")
            else:
                print(f"   ‚ùå Fichier non trouv√©")
                return False
                
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©ration: {e}")
            return False
        
        print(f"\n‚úÖ Test avec donn√©es r√©elles r√©ussi !")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return False

def main():
    """Fonction principale de test"""
    print("üöÄ TEST G√âN√âRATION DE RAPPORTS GLOBAL")
    print("=" * 60)
    
    # Tests
    test1 = test_report_generation()
    test2 = test_report_with_real_data()
    
    # R√©sum√©
    print(f"\n" + "=" * 60)
    print("üìä R√âSUM√â DES TESTS")
    print("=" * 60)
    
    tests = [
        ("G√©n√©ration avec donn√©es de test", test1),
        ("G√©n√©ration avec donn√©es r√©elles", test2)
    ]
    
    success_count = 0
    for test_name, result in tests:
        status = "‚úÖ R√âUSSI" if result else "‚ùå √âCHEC"
        print(f"   {test_name}: {status}")
        if result:
            success_count += 1
    
    print(f"\nüìà R√©sultat global: {success_count}/{len(tests)} tests r√©ussis")
    
    if success_count == len(tests):
        print("üéâ Tous les tests de g√©n√©ration de rapports sont r√©ussis !")
        print("‚úÖ La g√©n√©ration de rapports globale fonctionne parfaitement.")
        return True
    else:
        print("‚ö†Ô∏è Certains tests de g√©n√©ration de rapports ont √©chou√©.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 